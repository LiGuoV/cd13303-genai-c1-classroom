{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e672bb19",
      "metadata": {},
      "source": [
        "# Exercise: Teach an LLM to Spell with Group Relative Policy Optimization (GRPO)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e01691a",
      "metadata": {},
      "source": [
        "Large language models (LLMs) are notoriously bad at spelling. This is partly because tokenizers break words into smaller pieces, so the model learns about sub-word units rather than whole words and their spellings.\n",
        "\n",
        "In this exercise, you'll use Group Relative Policy Optimization (GRPO) and a technique called Parameter-Efficient Fine-Tuning (PEFT) with Low-Rank Adaptation (LoRA) to teach a small LLM how to spell words. This is a classic example of teaching a model a new skill that isn't well-represented in its pre-training data.\n",
        "\n",
        "## What you'll do in this notebook\n",
        "\n",
        "1.  **Setup**: Import libraries and configure the environment.\n",
        "2.  **Load the tokenizer and base model**: Use a small, instruction-tuned model as our starting point.\n",
        "3.  **Create the dataset**: Generate a simple dataset of words and their correct spellings.\n",
        "4.  **Evaluate the base model**: Test the model's spelling ability *before* fine-tuning to establish a baseline.\n",
        "5.  **Configure LoRA and train**: Attach a LoRA adapter to the model and fine-tune it on the spelling dataset.\n",
        "6.  **Evaluate the fine-tuned model**: Test the model again to see if its spelling has improved."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d04085e7",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "97437029",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Setup imports\n",
        "# No changes needed in this cell\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "# Use GPU, MPS, or CPU, in that order of preference\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # NVIDIA GPU\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")  # Apple Silicon\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "torch.set_num_threads(max(1, os.cpu_count() // 2))\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18f0a0d7",
      "metadata": {},
      "source": [
        "## Step 1. Load the tokenizer and base model\n",
        "\n",
        "The model `HuggingFaceTB/SmolLM2-135M-Instruct` is a small, instruction-tuned model that's suitable for this exercise. It has 135 million parameters, making it lightweight and efficient for fine-tuning. It's not the most powerful model, but it's a good choice for demonstrating the concepts of SFT and PEFT with LoRA, especially on a CPU or limited GPU resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f8028ac1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model parameters (total): 134515008\n"
          ]
        }
      ],
      "source": [
        "# Student task: Load the model and tokenizer, and copy the model to the device.\n",
        "# TODO: Complete the sections with **********\n",
        "\n",
        "# See: https://huggingface.co/docs/transformers/en/models\n",
        "# See: https://huggingface.co/docs/transformers/en/fast_tokenizers\n",
        "\n",
        "# Model ID for SmolLM2-135M-Instruct\n",
        "# model_id = \"***********\"\n",
        "model_id = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
        "\n",
        "# Load the tokenizer\n",
        "# tokenizer = \"***********\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "# Load the model\n",
        "# model = \"***********\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "# Copy the model to the device (GPU, MPS, or CPU)\n",
        "# model = \"***********\"\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Model parameters (total):\", sum(p.numel() for p in model.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6665787",
      "metadata": {},
      "source": [
        "## Step 2. Create the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "46de84a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a list of words of different lengths\n",
        "# No changes are needed in this cell.\n",
        "\n",
        "# fmt: off\n",
        "ALL_WORDS = [\n",
        "    \"idea\", \"glow\", \"rust\", \"maze\", \"echo\", \"wisp\", \"veto\", \"lush\", \"gaze\", \"knit\", \"fume\", \"plow\",\n",
        "    \"void\", \"oath\", \"grim\", \"crisp\", \"lunar\", \"fable\", \"quest\", \"verge\", \"brawn\", \"elude\", \"aisle\",\n",
        "    \"ember\", \"crave\", \"ivory\", \"mirth\", \"knack\", \"wryly\", \"onset\", \"mosaic\", \"velvet\", \"sphinx\",\n",
        "    \"radius\", \"summit\", \"banner\", \"cipher\", \"glisten\", \"mantle\", \"scarab\", \"expose\", \"fathom\",\n",
        "    \"tavern\", \"fusion\", \"relish\", \"lantern\", \"enchant\", \"torrent\", \"capture\", \"orchard\", \"eclipse\",\n",
        "    \"frescos\", \"triumph\", \"absolve\", \"gossipy\", \"prelude\", \"whistle\", \"resolve\", \"zealous\",\n",
        "    \"mirage\", \"aperture\", \"sapphire\",\n",
        "]\n",
        "# fmt: on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bbeab6e5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prompt': 'You spell word with hyphens between the letters like this W-O-R-D.\\nWord:\\ntriumph\\n\\nSpelling:\\n',\n",
              " 'completion': 'T-R-I-U-M-P-H.',\n",
              " 'word': 'triumph',\n",
              " 'spelling': 'T-R-I-U-M-P-H'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Student Task: Create a Hugging Face Dataset with the prompt that asks the model to spell the word\n",
        "# with hyphens between the letters.\n",
        "# TODO: Complete the sections with **********\n",
        "\n",
        "\n",
        "def generate_records():\n",
        "    for word in ALL_WORDS:\n",
        "        yield {\n",
        "            # We will use the GRPOTrainer which expects to receieve formatted prompts\n",
        "            # to pass to the LLM\n",
        "            # https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
        "            # \"**********\": f\"**********\",\n",
        "            # Before using GRPOTrainer, will run a few epochs of supervised-fine tuning (SFT)\n",
        "            # which can be useful to give an initial nudge to the model. Thus we need to provide\n",
        "            # the gold standard answer.\n",
        "            # See the documentation for more details:\n",
        "            # https://huggingface.co/docs/trl/en/sft_trainer#expected-dataset-type-and-format\n",
        "            # \"**********\": \"-\".join(word).upper() + \".\",\n",
        "            # GRPOTrainer does not expect a completion, but we can add extra columns to our dataset\n",
        "            # that our reward functions will use to grade the completions provided by the LLM.\n",
        "            \"prompt\": f\"You spell word with hyphens between the letters like this W-O-R-D.\\nWord:\\n{word}\\n\\nSpelling:\\n\",\n",
        "            'completion': \"-\".join(word).upper() + \".\",\n",
        "            'word': word,\n",
        "            'spelling': \"-\".join(word).upper(),\n",
        "        }\n",
        "\n",
        "\n",
        "ds = Dataset.from_generator(generate_records)\n",
        "\n",
        "ds = ds.train_test_split(test_size=0.1, seed=42)\n",
        "\n",
        "# Show the first item of the train split\n",
        "ds[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b6a9436",
      "metadata": {},
      "source": [
        "## Step 3. Evaluate the base model\n",
        "\n",
        "Before we fine-tune the model, let's see how it performs on the spelling task. We'll create a helper function to generate a spelling for a given word and compare it to the correct answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6581c243",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a helper function that will help us visualize the performance of the model\n",
        "# No changes needed in this cell\n",
        "\n",
        "\n",
        "def check_spelling(\n",
        "    model, tokenizer, prompt: str, actual_spelling: str, max_new_tokens: int = 20\n",
        ") -> (str, str):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    gen = model.generate(\n",
        "        **inputs, max_new_tokens=max_new_tokens, use_cache=False\n",
        "    )  # No parameters = greedy search\n",
        "    output = tokenizer.decode(gen[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract the generated spelling from the full output string\n",
        "    proposed_spelling = output.split(\"Spelling:\\n\")[-1].strip().split(\".\")[0].strip()\n",
        "\n",
        "    print(\n",
        "        f\"Proposed: {proposed_spelling} | Actual: {actual_spelling} \"\n",
        "        f\"| Matches: {'✅' if proposed_spelling == actual_spelling else '❌'}\"\n",
        "    )\n",
        "\n",
        "    # Remove hyphens for a character-by-character comparison\n",
        "    proposed_spelling = proposed_spelling.replace(\"-\", \"\")\n",
        "    actual_spelling = actual_spelling.replace(\"-\", \"\")\n",
        "\n",
        "    # Calculate the proportion of the spelling that was correct\n",
        "    num_correct = sum(1 for a, b in zip(actual_spelling, proposed_spelling) if a == b)\n",
        "\n",
        "    return num_correct / len(actual_spelling)  # Return proportion correct\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7642646c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proposed: trium | Actual: T-R-I-U-M-P-H | Matches: ❌\n",
            "Proposed: sapp | Actual: S-A-P-P-H-I-R-E | Matches: ❌\n",
            "Proposed: expose | Actual: E-X-P-O-S-E | Matches: ❌\n",
            "Proposed: fres | Actual: F-R-E-S-C-O-S | Matches: ❌\n",
            "Proposed: wisp | Actual: W-I-S-P | Matches: ❌\n",
            "Proposed: mi-er-ge\n",
            "\n",
            "Spelling | Actual: M-I-R-A-G-E | Matches: ❌\n",
            "Proposed: ivory | Actual: I-V-O-R-Y | Matches: ❌\n",
            "Proposed: onset\n",
            "\n",
            "Hyphen | Actual: O-N-S-E-T | Matches: ❌\n",
            "Proposed: elude | Actual: E-L-U-D-E | Matches: ❌\n",
            "Proposed: sphinx | Actual: S-P-H-I-N-X | Matches: ❌\n",
            "Proposed: brawn | Actual: B-R-A-W-N | Matches: ❌\n",
            "Proposed: goss | Actual: G-O-S-S-I-P-Y | Matches: ❌\n",
            "Proposed: enchant | Actual: E-N-C-H-A-N-T | Matches: ❌\n",
            "Proposed: tavern | Actual: T-A-V-E-R-N | Matches: ❌\n",
            "Proposed: whistle | Actual: W-H-I-S-T-L-E | Matches: ❌\n",
            "Proposed: W-O-R-D\n",
            "\n",
            "How would you like to see the word changed? | Actual: C-A-P-T-U-R-E | Matches: ❌\n",
            "Proposed: echo\n",
            "\n",
            "Word:\n",
            "echo\n",
            "\n",
            "Word:\n",
            "echo\n",
            "\n",
            "Word:\n",
            "echo | Actual: E-C-H-O | Matches: ❌\n",
            "Proposed: mirth | Actual: M-I-R-T-H | Matches: ❌\n",
            "Proposed: cris | Actual: C-R-I-S-P | Matches: ❌\n",
            "Proposed: zeal | Actual: Z-E-A-L-O-U-S | Matches: ❌\n",
            "0.0/20.0 words correct\n"
          ]
        }
      ],
      "source": [
        "# Student task: Evaluate the base model's spelling ability\n",
        "# We expect it to perform poorly, as it hasn't been trained for this task.\n",
        "\n",
        "proportion_correct = 0.0\n",
        "\n",
        "for example in ds[\"train\"].select(range(20)):\n",
        "    prompt = example[\"prompt\"]\n",
        "    spelling = example[\"spelling\"]\n",
        "    result = check_spelling(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        prompt=prompt,\n",
        "        actual_spelling=spelling,\n",
        "        max_new_tokens=20,\n",
        "    )\n",
        "    proportion_correct += result\n",
        "\n",
        "print(f\"{proportion_correct}/20.0 words correct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7c6563f",
      "metadata": {},
      "source": [
        "As expected, the base model is terrible at spelling. It mostly just repeats the word back. Now, let's fine-tune it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1e7ef15",
      "metadata": {},
      "source": [
        "## Step 4. Configure LoRA and train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "403a39e8",
      "metadata": {},
      "source": [
        "Let’s attach a LoRA adapter to the base model. We use a LoRA config so only a tiny fraction of parameters are trainable. Read more here: [LoRA](https://huggingface.co/docs/peft/main/en/conceptual_guides/lora)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d1b8d596",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable params BEFORE: 134,515,008 / 134,515,008 (100.00%)\n",
            "Trainable params AFTER: 3,686,400 / 138,201,408 (2.67%)\n"
          ]
        }
      ],
      "source": [
        "# Student task: Configure LoRA for a causal LM and wrap the model with get_peft_model\n",
        "# Complete the sections with **********\n",
        "\n",
        "# Print how many params are trainable at first\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(\n",
        "    f\"Trainable params BEFORE: {trainable:,} / {total:,} ({100 * trainable / total:.2f}%)\"\n",
        ")\n",
        "\n",
        "# See: https://huggingface.co/docs/peft/package_reference/lora\n",
        "# lora_config = LoraConfig(\n",
        "#     r=**********,                 # Rank of the update matrices. Lower value = fewer trainable parameters.\n",
        "#     lora_alpha=**********,        # LoRA scaling factor.\n",
        "#     lora_dropout=**********,      # Dropout probability for LoRA layers.\n",
        "#     bias=\"none\",\n",
        "#     task_type=**********,         # Causal Language Modeling.\n",
        "# )\n",
        "# # Wrap the base model with get_peft_model\n",
        "# model = get_peft_model(**********, **********)\n",
        "lora_config = LoraConfig(\n",
        "    r=64,                 # Rank of the update matrices. Lower value = fewer trainable parameters.\n",
        "    lora_alpha=16,        # LoRA scaling factor.\n",
        "    lora_dropout=0.05,      # Dropout probability for LoRA layers.\n",
        "    task_type=\"CAUSAL_LM\",         # Causal Language Modeling.\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Print the number of trainable parameters after applying LoRA\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(\n",
        "    f\"Trainable params AFTER: {trainable:,} / {total:,} ({100 * trainable / total:.2f}%)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30c5e91b",
      "metadata": {},
      "source": [
        "Now let’s set the training arguments. We'll use `SFTConfig` from the TRL library, which is a wrapper around the standard `TrainingArguments`. We keep epochs, batch size, and sequence length modest to finish training quickly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9341ba79",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [70/70 00:09, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Entropy</th>\n",
              "      <th>Num Tokens</th>\n",
              "      <th>Mean Token Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.064700</td>\n",
              "      <td>0.857524</td>\n",
              "      <td>2.435290</td>\n",
              "      <td>6833.000000</td>\n",
              "      <td>0.693884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.530800</td>\n",
              "      <td>0.730310</td>\n",
              "      <td>2.151160</td>\n",
              "      <td>13603.000000</td>\n",
              "      <td>0.730847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.430200</td>\n",
              "      <td>0.720356</td>\n",
              "      <td>2.081007</td>\n",
              "      <td>20407.000000</td>\n",
              "      <td>0.746976</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lgw/code/genai/.venv/lib/python3.13/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proposed: T-I-R-U-M-P-H | Actual: T-R-I-U-M-P-H | Matches: ❌\n",
            "Proposed: S-A-P-I-R-C-H | Actual: S-A-P-P-H-I-R-E | Matches: ❌\n",
            "Proposed: E-X-P-S-E-T | Actual: E-X-P-O-S-E | Matches: ❌\n",
            "Proposed: F-S-R-E-C-O-S | Actual: F-R-E-S-C-O-S | Matches: ❌\n",
            "Proposed: W-I-P-S | Actual: W-I-S-P | Matches: ❌\n",
            "Proposed: M-I-R-E-G | Actual: M-I-R-A-G-E | Matches: ❌\n",
            "Proposed: I-V-O-R-Y | Actual: I-V-O-R-Y | Matches: ✅\n",
            "Proposed: O-N-S-H-O-R-D | Actual: O-N-S-E-T | Matches: ❌\n",
            "Proposed: E-L-E-U-D | Actual: E-L-U-D-E | Matches: ❌\n",
            "Proposed: S-P-H-I-N-X | Actual: S-P-H-I-N-X | Matches: ✅\n",
            "Proposed: B-R-A-N-Y | Actual: B-R-A-W-N | Matches: ❌\n",
            "Proposed: G-S-O-P-I-Y | Actual: G-O-S-S-I-P-Y | Matches: ❌\n",
            "Proposed: E-N-C-H-A-N-T | Actual: E-N-C-H-A-N-T | Matches: ✅\n",
            "Proposed: T-A-A-N-R | Actual: T-A-V-E-R-N | Matches: ❌\n",
            "Proposed: W-H-I-S-E | Actual: W-H-I-S-T-L-E | Matches: ❌\n",
            "Proposed: C-U-P-A-R-E | Actual: C-A-P-T-U-R-E | Matches: ❌\n",
            "Proposed: E-C-H-O-R-E | Actual: E-C-H-O | Matches: ❌\n",
            "Proposed: M-I-R-T | Actual: M-I-R-T-H | Matches: ❌\n",
            "Proposed: C-R-I-S-P | Actual: C-R-I-S-P | Matches: ✅\n",
            "Proposed: Z-E-A-L-O-U-S | Actual: Z-E-A-L-O-U-S | Matches: ✅\n",
            "13.370238095238097/20.0 words correct\n"
          ]
        }
      ],
      "source": [
        "# Train the model for a few epochs using SFT before GRPO as in certain cases\n",
        "# they can work together synergystically.\n",
        "# See: https://arxiv.org/html/2507.08267v1\n",
        "# No changes needed here\n",
        "\n",
        "output_dir = \"data/model\"\n",
        "\n",
        "training_args = SFTConfig(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=10,\n",
        "    learning_rate=5 * 1e-4,\n",
        "    logging_steps=20,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=20,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=[],\n",
        "    fp16=False,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=ds[\"train\"],\n",
        "    eval_dataset=ds[\"test\"],\n",
        "    args=training_args,\n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "proportion_correct = 0.0\n",
        "\n",
        "for example in ds[\"train\"].select(range(20)):\n",
        "    prompt = example[\"prompt\"]\n",
        "    spelling = example[\"spelling\"]\n",
        "    result = check_spelling(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        prompt=prompt,\n",
        "        actual_spelling=spelling,\n",
        "        max_new_tokens=20,\n",
        "    )\n",
        "    proportion_correct += result\n",
        "\n",
        "print(f\"{proportion_correct}/20.0 words correct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d995e64",
      "metadata": {},
      "source": [
        "The number of words has slightly increased. Let's try training using GRPO now.\n",
        "\n",
        "First let's create some reward functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dd8e58bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Student Task: Create a helper function proportion_correct that takes a word and\n",
        "# a proposed spelling from the LLM and returns a score where every matched character\n",
        "# adds +1 and every  mismatched character subtracts 1 from the reward--including the\n",
        "# hyphens.\n",
        "# TODO: Replace occurences of **********\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "def proportion_correct(word, proposed_spelling):\n",
        "    correct_spelling = \"-\".join(word).upper()\n",
        "\n",
        "    score = 0.0\n",
        "\n",
        "    # Pad to the same length to handle extra characters\n",
        "    max_len = max(len(correct_spelling), len(proposed_spelling))\n",
        "    proposed_spelling_padded = proposed_spelling.ljust(max_len, \" \")\n",
        "    correct_spelling_padded = correct_spelling.ljust(max_len, \" \")\n",
        "\n",
        "    for a, b in zip(correct_spelling_padded, proposed_spelling_padded):\n",
        "        # Add 1 for matched characters, and subtract one for mismatched\n",
        "        # **********\n",
        "        if a == b:\n",
        "            score += 1\n",
        "        else:\n",
        "            score -= 1\n",
        "\n",
        "\n",
        "    return score / (\n",
        "        len(correct_spelling)\n",
        "    )  # Normalize by length of spelling, including dashes\n",
        "\n",
        "\n",
        "assert proportion_correct(\"hello\", \"H-E-L-L-O\") == 9 / 9\n",
        "assert proportion_correct(\"hello\", \"H-E-L-\") == 3 / 9\n",
        "assert proportion_correct(\"hello\", \"H-E-L-L-O!\") == 8 / 9\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "10e1457a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====\n",
            "Completion example first line: hello -> H-E-L-L-O\n",
            "Spelling mean and std: 0.741 +/- 0.292\n"
          ]
        }
      ],
      "source": [
        "# Create a `reward_spelling` function that receives a batch of completions and the associated word values\n",
        "# No changes needed here\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def reward_spelling(completions, word, **kwargs):\n",
        "    \"\"\"Reward function that rewards completions with more unique letters.\"\"\"\n",
        "\n",
        "    completion_strings = [\n",
        "        completion.split(\"\\n\")[0].strip() for completion in completions\n",
        "    ]\n",
        "    words = [w for w in word]\n",
        "\n",
        "    rewards = [proportion_correct(w, c) for w, c in zip(words, completion_strings)]\n",
        "\n",
        "    # When training, GRPO will pass multiple completions and words to this function.\n",
        "    # We print just the first one to observe what is happening under the hood.\n",
        "    print(\"=====\")\n",
        "    print(\n",
        "        \"Completion example first line:\",\n",
        "        words[0],\n",
        "        \"->\",\n",
        "        completion_strings[0].strip().split(\"\\n\")[0].strip(),\n",
        "    )\n",
        "    print(f\"Spelling mean and std: {np.mean(rewards):.3f} +/- {np.std(rewards):.3f}\")\n",
        "    return rewards\n",
        "\n",
        "\n",
        "assert reward_spelling(\n",
        "    completions=[\n",
        "        \"H-E-L-L-O\",\n",
        "        \"H-E-L-\",\n",
        "        \"H-E-L-L-O!\",\n",
        "    ],\n",
        "    word=[\n",
        "        \"hello\",\n",
        "        \"hello\",\n",
        "        \"hello\",\n",
        "    ],\n",
        ") == [1, 3 / 9, 8 / 9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9b98d1ba",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Letter-dash-letter rewards mean and std: 0.333 +/- 0.471\n"
          ]
        }
      ],
      "source": [
        "# Student task: Create a reward of 1.0 for completions starting with a string\n",
        "# formatted like X-Y-Z else return 0.0\n",
        "# TODO: Replace sections marked with **********\n",
        "\n",
        "\n",
        "def reward_response_in_form_of_letter_dash_letter(completions, word, **kwargs):\n",
        "    \"\"\"Reward function that gives a bonus for completions in the form of LETTER-DASH-LETTER.\"\"\"\n",
        "    pattern = re.compile(r\"^([A-Z]-)+[A-Z]\")  # Pattern for LETTER-DASH-LETTER\n",
        "\n",
        "    words = [w for w in word]\n",
        "\n",
        "    # Normalize the completions, taking the first line and removing extra whitespace\n",
        "    completion_strings = [\n",
        "        completion.split(\"\\n\")[0].strip() for completion in completions\n",
        "    ]\n",
        "\n",
        "    # Create a list of rewards corresponding to completions\n",
        "    # Each completion that matches the pattern should receive 1.0,\n",
        "    # else 0.0\n",
        "    # rewards = [\n",
        "    #     **********\n",
        "    # ]\n",
        "\n",
        "    # <<< START COMPLETION SECTION\n",
        "    rewards = [\n",
        "        1.0 if pattern.match(c) else 0.0 for w, c in zip(words, completion_strings)\n",
        "    ]\n",
        "    # >>> END COMPLETION SECTION\n",
        "\n",
        "    print(\n",
        "        f\"Letter-dash-letter rewards mean and std: {np.mean(rewards):.3f} +/- {np.std(rewards):.3f}\"\n",
        "    )\n",
        "    return rewards\n",
        "\n",
        "\n",
        "assert reward_response_in_form_of_letter_dash_letter(\n",
        "    completions=[\n",
        "        \"H-E-L-L-O\",\n",
        "        \"hello\",\n",
        "        \"Hi!\",\n",
        "    ],\n",
        "    word=[\n",
        "        \"hello\",\n",
        "        \"hello\",\n",
        "        \"hello\",\n",
        "    ],\n",
        ") == [1, 0, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f8a9d1e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====\n",
            "Completion example first line: mirth -> M-I-R-Y.\n",
            "Spelling mean and std: 0.311 +/- 0.207\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [270/270 01:10, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.039100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>-0.018900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>-0.006900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.025200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.017900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>-0.021900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>-0.025700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>-0.007200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.017000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.008200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>-0.009900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.014400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.042000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.057700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>-0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>-0.041300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.029100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.042500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>-0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>-0.014100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>-0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>-0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>-0.011200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>-0.019000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>-0.016800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>0.027100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>-0.009300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.005900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.010800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>-0.010300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>-0.024200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>-0.040000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>0.010800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>-0.019600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>-0.006800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>-0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>0.010700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>0.027200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>-0.001800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>0.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>-0.012400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>-0.011700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>0.010200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>-0.036000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>-0.005800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====\n",
            "Completion example first line: mantle -> M-A-T-I-R-N-H.\n",
            "Spelling mean and std: -0.063 +/- 0.754\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: summit -> M-S-U-T-I-N.\n",
            "Spelling mean and std: -0.159 +/- 0.426\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: absolve -> A-B-C-E-L-O-V-E.\n",
            "Spelling mean and std: 0.315 +/- 0.300\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ivory -> I-V-O-R-Y.\n",
            "Spelling mean and std: 0.358 +/- 0.443\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: resolve -> R-I-S-E.\n",
            "Spelling mean and std: 0.144 +/- 0.243\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: tavern -> T-A-H-A-N.\n",
            "Spelling mean and std: 0.101 +/- 0.125\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: brawn -> B-R-W-N.\n",
            "Spelling mean and std: 0.153 +/- 0.248\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: sapphire -> S-A-P-S-K-R-I.\n",
            "Spelling mean and std: 0.266 +/- 0.271\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fathom -> F-H-M-P.\n",
            "Spelling mean and std: 0.065 +/- 0.397\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: rust -> R-O-T.\n",
            "Spelling mean and std: -0.007 +/- 0.200\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: oath -> O-A-H-R-D.\n",
            "Spelling mean and std: 0.102 +/- 0.115\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: crisp -> C-R-S-I-P.\n",
            "Spelling mean and std: 0.542 +/- 0.269\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: prelude -> P-R-E-L-U-N.\n",
            "Spelling mean and std: 0.157 +/- 0.267\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mosaic -> M-A-S-I-R-E.\n",
            "Spelling mean and std: 0.341 +/- 0.379\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: glow -> G-L-O-V-E.\n",
            "Spelling mean and std: 0.195 +/- 0.296\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: knit -> n-K-I-T.\n",
            "Spelling mean and std: 0.021 +/- 0.404\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: verge -> V-E-R-G-E.\n",
            "Spelling mean and std: 0.371 +/- 0.322\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mirage -> M-I-A-R-R-I-A.\n",
            "Spelling mean and std: 0.261 +/- 0.255\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: void -> V-A-T.\n",
            "Spelling mean and std: -0.034 +/- 0.273\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: echo -> E-C-E-R-H.\n",
            "Spelling mean and std: 0.250 +/- 0.362\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: frescos -> F-S-R-E-C-S.\n",
            "Spelling mean and std: 0.038 +/- 0.128\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: torrent -> T-O-R-A-C.\n",
            "Spelling mean and std: 0.164 +/- 0.237\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: relish -> R-E-S-L-E.\n",
            "Spelling mean and std: 0.100 +/- 0.143\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: grim -> G-R-M.\n",
            "Spelling mean and std: 0.163 +/- 0.271\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: cipher -> C-F-E-P.\n",
            "Spelling mean and std: 0.003 +/- 0.231\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: elude -> E-L-E-A-U.\n",
            "Spelling mean and std: 0.221 +/- 0.214\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fusion -> F-U-S-R-A-L.\n",
            "Spelling mean and std: -0.034 +/- 0.198\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: onset -> O-N-S-I.\n",
            "Spelling mean and std: 0.377 +/- 0.570\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: sphinx -> S-P-H-A-N.\n",
            "Spelling mean and std: 0.159 +/- 0.180\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: prelude -> P-R-E-L-I-d.\n",
            "Spelling mean and std: 0.316 +/- 0.160\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: grim -> G-R-H-I.\n",
            "Spelling mean and std: 0.272 +/- 0.239\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: brawn -> B-A-R-Y.\n",
            "Spelling mean and std: 0.173 +/- 0.340\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: sapphire -> S-P-A-L-I-C.\n",
            "Spelling mean and std: 0.135 +/- 0.166\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ivory -> I-V-O-R-H-C-E.\n",
            "Spelling mean and std: 0.225 +/- 0.056\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: velvet -> V-L-E-V-T-C.\n",
            "Spelling mean and std: 0.470 +/- 0.287\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: banner -> B-A-N-N-B-R.\n",
            "Spelling mean and std: 0.373 +/- 0.356\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aperture -> A-P-R-E-T-A-R-T-E.\n",
            "Spelling mean and std: 0.260 +/- 0.337\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mantle -> M-A-T-L-E.\n",
            "Spelling mean and std: 0.098 +/- 0.554\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: verge -> V-E-R-G.\n",
            "Spelling mean and std: 0.345 +/- 0.336\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: frescos -> F-R-S-C-O-S-S.\n",
            "Spelling mean and std: 0.183 +/- 0.144\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ember -> E-M-B-I-A.\n",
            "Spelling mean and std: 0.431 +/- 0.225\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fathom -> F-H-A-M-C-I-S.\n",
            "Spelling mean and std: 0.284 +/- 0.271\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: scarab -> S-A-C-R-B-A.\n",
            "Spelling mean and std: 0.299 +/- 0.217\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: void -> V-A-T.\n",
            "Spelling mean and std: 0.037 +/- 0.167\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: elude -> E-L-A-U-D.\n",
            "Spelling mean and std: 0.097 +/- 0.130\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: idea -> I-D-E-A-R-D.\n",
            "Spelling mean and std: -0.091 +/- 0.347\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aisle -> A-I-S-S-L-e.\n",
            "Spelling mean and std: 0.254 +/- 0.334\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: triumph -> T-I-R-R-L-P.\n",
            "Spelling mean and std: 0.269 +/- 0.224\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: radius -> R-A-I-N-S.\n",
            "Spelling mean and std: -0.010 +/- 0.206\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: eclipse -> E-C-S-L-E-P.\n",
            "Spelling mean and std: 0.010 +/- 0.118\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: gaze -> G-E-A-Z.\n",
            "Spelling mean and std: 0.343 +/- 0.340\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: echo -> E-C-H-R.\n",
            "Spelling mean and std: 0.459 +/- 0.177\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: zealous -> Z-E-L-A-Z-O.\n",
            "Spelling mean and std: 0.198 +/- 0.408\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: brawn -> B-R-A-W-N.\n",
            "Spelling mean and std: 0.503 +/- 0.309\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: gaze -> G-A-Z-E.\n",
            "Spelling mean and std: 0.376 +/- 0.383\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fusion -> F-U-S-R-A-F.\n",
            "Spelling mean and std: 0.088 +/- 0.205\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: sapphire -> S-A-P-L-S-A-P-R-I-H.\n",
            "Spelling mean and std: 0.586 +/- 0.325\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: lantern -> L-A-N-P-R-T.\n",
            "Spelling mean and std: 0.183 +/- 0.210\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: wisp -> W-P-I-S.\n",
            "Spelling mean and std: 0.148 +/- 0.149\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mirth -> M-I-R-R-M.\n",
            "Spelling mean and std: 0.523 +/- 0.206\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: knit -> W-I-N-L-T.\n",
            "Spelling mean and std: -0.299 +/- 0.792\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: plow -> P-L-O-R.\n",
            "Spelling mean and std: 0.317 +/- 0.389\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: gossipy -> G-S-O-G-G-G-P-O-I-Z-Y.\n",
            "Spelling mean and std: -0.047 +/- 0.382\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mantle -> M-A-N-T-L-R-E.\n",
            "Spelling mean and std: 0.359 +/- 0.220\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mosaic -> M-A-R-ISS-k-O-R-T.\n",
            "Spelling mean and std: -0.140 +/- 0.303\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: resolve -> R-I-S-A-L-S.\n",
            "Spelling mean and std: 0.255 +/- 0.228\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: triumph -> T-I-R-M-U-R-L-V-H-P.\n",
            "Spelling mean and std: -0.096 +/- 0.317\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: relish -> R-E-L-S-H-R-L.\n",
            "Spelling mean and std: 0.071 +/- 0.210\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: banner -> B-A-N-N-B-R-N.\n",
            "Spelling mean and std: 0.078 +/- 0.346\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ember -> E-M-B-A.\n",
            "Spelling mean and std: 0.036 +/- 0.504\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: radius -> R-A-S-M-R-D.\n",
            "Spelling mean and std: 0.102 +/- 0.278\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: prelude -> W-A-L-P-R-I-D-L.\n",
            "Spelling mean and std: 0.095 +/- 0.236\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: zealous -> Z-E-A-L-O-W-R-A.\n",
            "Spelling mean and std: -0.023 +/- 0.631\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: oath -> O-A-H-T.\n",
            "Spelling mean and std: 0.226 +/- 0.307\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: orchard -> R-O-C-H-A-R-D.\n",
            "Spelling mean and std: 0.317 +/- 0.222\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fume -> F-U-M-E.\n",
            "Spelling mean and std: 0.536 +/- 0.318\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: rust -> R-T-R-S.\n",
            "Spelling mean and std: 0.067 +/- 0.136\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ivory -> I-V-A-Y-O.\n",
            "Spelling mean and std: 0.597 +/- 0.254\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mirage -> M-I-R-G-R.\n",
            "Spelling mean and std: 0.370 +/- 0.176\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fathom -> F-A-M-H-S.\n",
            "Spelling mean and std: 0.164 +/- 0.142\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: veto -> V-E-TO.\n",
            "Spelling mean and std: 0.542 +/- 0.194\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mosaic -> M-A-R-S-I-C.\n",
            "Spelling mean and std: 0.398 +/- 0.433\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: velvet -> V-L-E-V-T.\n",
            "Spelling mean and std: 0.288 +/- 0.183\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: glow -> G-I-L-O-W.\n",
            "Spelling mean and std: 0.372 +/- 0.371\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: absolve -> A-B-C-E-R-V.\n",
            "Spelling mean and std: 0.058 +/- 0.179\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: orchard -> O-R-C-A-R-D.\n",
            "Spelling mean and std: 0.436 +/- 0.285\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aisle -> A-I-S-L-E.\n",
            "Spelling mean and std: 0.505 +/- 0.257\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: zealous -> Z-E-A-L-O-W-S.\n",
            "Spelling mean and std: -0.095 +/- 0.724\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: rust -> R-T-S-O-R.\n",
            "Spelling mean and std: 0.036 +/- 0.223\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ivory -> I-V-A-O-R-Y.\n",
            "Spelling mean and std: 0.427 +/- 0.255\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fusion -> F-A-S-S-T-R-U-L.\n",
            "Spelling mean and std: 0.091 +/- 0.164\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: lunar -> L-U-R-N-L-A.\n",
            "Spelling mean and std: 0.153 +/- 0.242\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: radius -> R-A-S-Z-R-D.\n",
            "Spelling mean and std: 0.191 +/- 0.163\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: eclipse -> E-C-L-O-S-P.\n",
            "Spelling mean and std: 0.271 +/- 0.125\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fathom -> F-A-M-T-H.\n",
            "Spelling mean and std: 0.260 +/- 0.136\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: grim -> G-R-M-H.\n",
            "Spelling mean and std: 0.500 +/- 0.371\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: tavern -> T-A-A-B-R-N.\n",
            "Spelling mean and std: 0.284 +/- 0.234\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: wisp -> W-I-P-S-W.\n",
            "Spelling mean and std: 0.325 +/- 0.220\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fume -> F-U-M-E.\n",
            "Spelling mean and std: 0.429 +/- 0.446\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: gaze -> G-A-Z-E.\n",
            "Spelling mean and std: 0.275 +/- 0.661\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: prelude -> P-R-L-E-U-L.\n",
            "Spelling mean and std: 0.245 +/- 0.155\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: resolve -> R-I-S-S-L-E.\n",
            "Spelling mean and std: 0.309 +/- 0.316\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: knit -> W-I-L-N-T.\n",
            "Spelling mean and std: 0.196 +/- 0.587\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: echo -> E-C-H-R-O.\n",
            "Spelling mean and std: 0.476 +/- 0.160\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: summit -> S-M-U-T-T.\n",
            "Spelling mean and std: 0.349 +/- 0.217\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: frescos -> F-R-S-S-C-O-S.\n",
            "Spelling mean and std: 0.269 +/- 0.329\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aperture -> A-R-P-P-T-R-U-R.\n",
            "Spelling mean and std: 0.227 +/- 0.139\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: gossipy -> G-O-S-S-O-P-I.\n",
            "Spelling mean and std: 0.210 +/- 0.188\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: zealous -> Z-E-A-L-O-W.\n",
            "Spelling mean and std: 0.427 +/- 0.320\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: idea -> I-D-O-S-H.\n",
            "Spelling mean and std: 0.286 +/- 0.535\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: relish -> R-E-L-S-S-R.\n",
            "Spelling mean and std: 0.352 +/- 0.173\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fume -> F-M-U-E.\n",
            "Spelling mean and std: 0.420 +/- 0.257\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: frescos -> F-R-S-S-C-O-S.\n",
            "Spelling mean and std: 0.746 +/- 0.132\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fusion -> F-U-S-R-S.\n",
            "Spelling mean and std: 0.403 +/- 0.216\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: velvet -> V-E-L-O-T-V.\n",
            "Spelling mean and std: 0.256 +/- 0.128\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: glow -> G-L-O-W.\n",
            "Spelling mean and std: 0.857 +/- 0.000\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: whistle -> W-H-I-S-C-H.\n",
            "Spelling mean and std: -0.104 +/- 0.302\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mirth -> M-I-R-R-T.\n",
            "Spelling mean and std: 0.375 +/- 0.123\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fathom -> F-I-M-H-T.\n",
            "Spelling mean and std: 0.197 +/- 0.248\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: absolve -> A-B-R-E-S-L-E.\n",
            "Spelling mean and std: 0.192 +/- 0.192\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: banner -> B-A-N-N-R-N.\n",
            "Spelling mean and std: 0.289 +/- 0.212\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: triumph -> T-R-I-M-U-R-P.\n",
            "Spelling mean and std: 0.363 +/- 0.252\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: scarab -> S-A-R-C-R-A.\n",
            "Spelling mean and std: 0.299 +/- 0.387\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: onset -> O-N-S-T.\n",
            "Spelling mean and std: 0.238 +/- 0.139\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: tavern -> T-A-A-T-R-B.\n",
            "Spelling mean and std: 0.610 +/- 0.247\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: oath -> O-A-T-H.\n",
            "Spelling mean and std: 0.630 +/- 0.237\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: sphinx -> S-P-H-I-N-X.\n",
            "Spelling mean and std: 0.381 +/- 0.202\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: rust -> R-U-T-S.\n",
            "Spelling mean and std: 0.401 +/- 0.143\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aperture -> A-R-P-E-R-T-R-U-T.\n",
            "Spelling mean and std: 0.211 +/- 0.104\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: brawn -> B-R-A-W-R.\n",
            "Spelling mean and std: 0.537 +/- 0.278\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: elude -> E-L-U-D-E.\n",
            "Spelling mean and std: 0.611 +/- 0.309\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: orchard -> O-R-C-H-R-D.\n",
            "Spelling mean and std: 0.340 +/- 0.069\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: enchant -> E-N-C-H-P-T.\n",
            "Spelling mean and std: 0.154 +/- 0.188\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: radius -> R-A-S-M-R-D.\n",
            "Spelling mean and std: -0.016 +/- 0.175\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: grim -> G-R-I-M.\n",
            "Spelling mean and std: 0.515 +/- 0.300\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: summit -> S-U-M-T-I-T.\n",
            "Spelling mean and std: 0.466 +/- 0.184\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: tavern -> T-A-A-R-B.\n",
            "Spelling mean and std: 0.549 +/- 0.241\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: absolve -> A-B-C-E-R-O.\n",
            "Spelling mean and std: 0.477 +/- 0.381\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ivory -> I-V-O-R-Y.\n",
            "Spelling mean and std: 0.659 +/- 0.289\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mirth -> M-E-R-I-T.\n",
            "Spelling mean and std: 0.448 +/- 0.192\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: knit -> I-N-K-T.\n",
            "Spelling mean and std: -0.282 +/- 1.562\n",
            "Letter-dash-letter rewards mean and std: 0.750 +/- 0.433\n",
            "=====\n",
            "Completion example first line: aperture -> A-P-R-E-T-P-R-T-R.\n",
            "Spelling mean and std: 0.320 +/- 0.053\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: velvet -> V-E-L-O-V-T.\n",
            "Spelling mean and std: 0.182 +/- 0.280\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fume -> F-U-M-E.\n",
            "Spelling mean and std: 0.409 +/- 0.457\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: elude -> E-L-U-D-E.\n",
            "Spelling mean and std: 0.490 +/- 0.404\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ember -> E-M-B-U-R-A.\n",
            "Spelling mean and std: 0.466 +/- 0.214\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: crisp -> C-R-I-S-P-S.\n",
            "Spelling mean and std: 0.593 +/- 0.208\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: prelude -> P-R-E-L-I-D.\n",
            "Spelling mean and std: 0.659 +/- 0.202\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: torrent -> T-O-R-A-C-R-N.\n",
            "Spelling mean and std: 0.538 +/- 0.207\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: relish -> R-E-L-S-H-R.\n",
            "Spelling mean and std: 0.221 +/- 0.104\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: banner -> B-A-N-N-R-O.\n",
            "Spelling mean and std: 0.512 +/- 0.099\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: scarab -> S-A-R-K-A-B.\n",
            "Spelling mean and std: 0.565 +/- 0.299\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: onset -> O-N-S-L-D.\n",
            "Spelling mean and std: 0.544 +/- 0.112\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: oath -> O-A-T-H.\n",
            "Spelling mean and std: 0.549 +/- 0.240\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: resolve -> R-E-S-I-L-S.\n",
            "Spelling mean and std: 0.309 +/- 0.137\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: whistle -> W-H-I-C-T.\n",
            "Spelling mean and std: -0.030 +/- 0.211\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: capture -> C-U-P-R-E-T.\n",
            "Spelling mean and std: 0.050 +/- 0.275\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: orchard -> O-R-C-H-R-D.\n",
            "Spelling mean and std: 0.298 +/- 0.256\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aisle -> A-I-S-E-L-e.\n",
            "Spelling mean and std: 0.313 +/- 0.312\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: verge -> V-E-R-G-E.\n",
            "Spelling mean and std: 0.790 +/- 0.215\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: gaze -> G-A-Z-E.\n",
            "Spelling mean and std: 0.270 +/- 0.375\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: gossipy -> G-O-S-S-O-P-I.\n",
            "Spelling mean and std: 0.533 +/- 0.369\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: velvet -> V-E-L-O-V-T.\n",
            "Spelling mean and std: 0.295 +/- 0.256\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: grim -> R-E-G-M.\n",
            "Spelling mean and std: 0.334 +/- 0.320\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: capture -> C-U-P-R-E-T.\n",
            "Spelling mean and std: 0.000 +/- 0.266\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: rust -> R-T-O-R.\n",
            "Spelling mean and std: 0.411 +/- 0.449\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: banner -> B-A-N-N-R-O.\n",
            "Spelling mean and std: 0.724 +/- 0.144\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: elude -> E-L-U-D-E.\n",
            "Spelling mean and std: 0.412 +/- 0.280\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: torrent -> T-O-R-U-R-T.\n",
            "Spelling mean and std: 0.562 +/- 0.259\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mosaic -> M-A-C-I-S-T.\n",
            "Spelling mean and std: 0.155 +/- 0.319\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: triumph -> T-I-R-U-M-P.\n",
            "Spelling mean and std: 0.363 +/- 0.225\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mirth -> M-I-R-T.\n",
            "Spelling mean and std: 0.563 +/- 0.143\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: expose -> E-X-P-S-O.\n",
            "Spelling mean and std: 0.213 +/- 0.081\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aperture -> A-P-R-E-T-O-R.\n",
            "Spelling mean and std: 0.373 +/- 0.135\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: absolve -> A-B-I-C-E.\n",
            "Spelling mean and std: 0.162 +/- 0.148\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: orchard -> O-R-CH-A-D.\n",
            "Spelling mean and std: 0.421 +/- 0.308\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mantle -> M-A-N-T-R-L.\n",
            "Spelling mean and std: 0.265 +/- 0.160\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: relish -> R-E-L-S-H.\n",
            "Spelling mean and std: 0.336 +/- 0.127\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: scarab -> S-A-C-R-R-B.\n",
            "Spelling mean and std: 0.281 +/- 0.319\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: resolve -> R-E-S-L-O-S.\n",
            "Spelling mean and std: 0.258 +/- 0.047\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: brawn -> B-R-A-N-W-N.\n",
            "Spelling mean and std: 0.694 +/- 0.282\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ember -> E-B-U-M.\n",
            "Spelling mean and std: 0.259 +/- 0.321\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: onset -> O-N-T-S.\n",
            "Spelling mean and std: 0.637 +/- 0.261\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: idea -> I-D-O-E.\n",
            "Spelling mean and std: 0.500 +/- 0.371\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: knit -> L-I-N-T.\n",
            "Spelling mean and std: 0.158 +/- 0.173\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: maze -> M-A-Z-E.\n",
            "Spelling mean and std: 0.588 +/- 0.293\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: verge -> V-E-R-G-E.\n",
            "Spelling mean and std: 0.604 +/- 0.287\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: sphinx -> S-P-H-I-N-F.\n",
            "Spelling mean and std: 0.643 +/- 0.206\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: rust -> R-T-O-R.\n",
            "Spelling mean and std: 0.164 +/- 0.254\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: torrent -> T-O-R-U-R-N.\n",
            "Spelling mean and std: 0.387 +/- 0.204\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ember -> E-M-B-U-R.\n",
            "Spelling mean and std: 0.465 +/- 0.171\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fathom -> F-A-M-T-H.\n",
            "Spelling mean and std: 0.023 +/- 0.060\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: cipher -> C-I-F-P-A-M.\n",
            "Spelling mean and std: 0.520 +/- 0.182\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: verge -> V-E-R-G-E.\n",
            "Spelling mean and std: 0.495 +/- 0.342\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: brawn -> B-R-A-N-W-R.\n",
            "Spelling mean and std: 0.288 +/- 0.341\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ivory -> I-V-O-R-Y.\n",
            "Spelling mean and std: 0.667 +/- 0.222\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: grim -> G-R-I-M.\n",
            "Spelling mean and std: 0.680 +/- 0.226\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fume -> F-U-E-M.\n",
            "Spelling mean and std: 0.653 +/- 0.250\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: lantern -> L-A-N-N-T-R.\n",
            "Spelling mean and std: 0.469 +/- 0.207\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: lunar -> L-U-N-R-M.\n",
            "Spelling mean and std: 0.417 +/- 0.197\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: absolve -> A-Z-I-B-A-R-E.\n",
            "Spelling mean and std: 0.217 +/- 0.222\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: onset -> O-N-S-L-O.\n",
            "Spelling mean and std: 0.583 +/- 0.247\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: scarab -> S-A-R-C-A-B.\n",
            "Spelling mean and std: 0.341 +/- 0.192\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mantle -> M-A-N-T-R-L.\n",
            "Spelling mean and std: 0.558 +/- 0.202\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: oath -> O-A-T-H.\n",
            "Spelling mean and std: 0.706 +/- 0.151\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: zealous -> Z-E-A-L-O-W-L-S.\n",
            "Spelling mean and std: 0.584 +/- 0.152\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: maze -> M-A-Z-S.\n",
            "Spelling mean and std: 0.500 +/- 0.343\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: triumph -> T-I-R-O-M-P.\n",
            "Spelling mean and std: 0.630 +/- 0.272\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: relish -> R-E-L-S-R-L.\n",
            "Spelling mean and std: 0.227 +/- 0.129\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: frescos -> F-R-S-E-S-C-O.\n",
            "Spelling mean and std: 0.308 +/- 0.255\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: capture -> C-U-P-R-A-T.\n",
            "Spelling mean and std: 0.181 +/- 0.130\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: plow -> P-L-O-W.\n",
            "Spelling mean and std: 0.383 +/- 0.543\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: wisp -> W-I-P-S.\n",
            "Spelling mean and std: 0.571 +/- 0.286\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aperture -> A-P-R-E-T-T-O-R.\n",
            "Spelling mean and std: 0.373 +/- 0.161\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: whistle -> W-H-I-C-T.\n",
            "Spelling mean and std: 0.115 +/- 0.315\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: sapphire -> S-A-P-P-L-E-R.\n",
            "Spelling mean and std: 0.582 +/- 0.220\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: void -> V-O-N-T.\n",
            "Spelling mean and std: 0.365 +/- 0.079\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: triumph -> T.I.R.U.M.P.H.\n",
            "Spelling mean and std: 0.337 +/- 0.282\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: summit -> S-U-M-T-M.\n",
            "Spelling mean and std: 0.557 +/- 0.338\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: eclipse -> E-C-L-S-O-P.\n",
            "Spelling mean and std: 0.544 +/- 0.313\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: veto -> V-E-T-O.\n",
            "Spelling mean and std: 0.542 +/- 0.323\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: enchant -> E-N-C-H-A-T.\n",
            "Spelling mean and std: 0.386 +/- 0.242\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: scarab -> S-A-C-R-A-B.\n",
            "Spelling mean and std: 0.724 +/- 0.193\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mirage -> M- I- R- G- R- E- A.\n",
            "Spelling mean and std: 0.315 +/- 0.408\n",
            "Letter-dash-letter rewards mean and std: 0.875 +/- 0.331\n",
            "=====\n",
            "Completion example first line: gossipy -> G-O-S-S-O-P-I.\n",
            "Spelling mean and std: 0.686 +/- 0.171\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: onset -> O-N-S-T.\n",
            "Spelling mean and std: 0.242 +/- 0.115\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aperture -> A-P-R-E-T-R-T-O.\n",
            "Spelling mean and std: 0.230 +/- 0.161\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: maze -> M-A-Z-E.\n",
            "Spelling mean and std: 0.393 +/- 0.406\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: resolve -> R-E-S-S-L-I-S.\n",
            "Spelling mean and std: 0.285 +/- 0.144\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ember -> E-M-B-U-E.\n",
            "Spelling mean and std: 0.396 +/- 0.225\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: banner -> B-A-N-N-R-O.\n",
            "Spelling mean and std: 0.477 +/- 0.202\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: knit -> L-I-N-T.\n",
            "Spelling mean and std: 0.250 +/- 0.256\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fathom -> F-A-M-T-H.\n",
            "Spelling mean and std: 0.467 +/- 0.425\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: whistle -> W-H-I-C-T.\n",
            "Spelling mean and std: 0.355 +/- 0.208\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: relish -> R-E-L-S-R-L.\n",
            "Spelling mean and std: 0.278 +/- 0.098\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: echo -> E-C-H-R.\n",
            "Spelling mean and std: 0.427 +/- 0.255\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: crisp -> C-R-I-S-P.\n",
            "Spelling mean and std: 0.675 +/- 0.243\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: orchard -> O-R-H-C-O-R-D.\n",
            "Spelling mean and std: 0.736 +/- 0.163\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: brawn -> B-R-A-N-W.\n",
            "Spelling mean and std: 0.554 +/- 0.224\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mantle -> M-A-N-T-L-R.\n",
            "Spelling mean and std: 0.763 +/- 0.168\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: rust -> R-T-O-R.\n",
            "Spelling mean and std: 0.385 +/- 0.385\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mosaic -> M-A-R-I-S-T.\n",
            "Spelling mean and std: 0.239 +/- 0.111\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: cipher -> C-I-P-F-H.\n",
            "Spelling mean and std: 0.336 +/- 0.168\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: capture -> C-U-R-P-S-H.\n",
            "Spelling mean and std: 0.096 +/- 0.171\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: lantern -> L-A-N-T-R-N.\n",
            "Spelling mean and std: 0.481 +/- 0.120\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: veto -> V-E-T-O.\n",
            "Spelling mean and std: 0.610 +/- 0.247\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: echo -> E-C-H-E.\n",
            "Spelling mean and std: 0.503 +/- 0.183\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: summit -> S-U-M-T-I-M.\n",
            "Spelling mean and std: 0.388 +/- 0.236\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fathom -> F-A-M-T-H.\n",
            "Spelling mean and std: 0.094 +/- 0.125\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mantle -> M-A-N-T-L-R.\n",
            "Spelling mean and std: 0.443 +/- 0.344\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: zealous -> Z-E-A-L-O-W-S.\n",
            "Spelling mean and std: 0.624 +/- 0.263\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: elude -> E-L-U-D-E.\n",
            "Spelling mean and std: 0.710 +/- 0.303\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: aperture -> A-P-R-E-T-O-R-T.\n",
            "Spelling mean and std: 0.288 +/- 0.182\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: plow -> P-L-O-W.\n",
            "Spelling mean and std: 0.792 +/- 0.065\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: rust -> R-T-O-R.\n",
            "Spelling mean and std: 0.125 +/- 0.163\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: torrent -> T-O-R-U-R-N.\n",
            "Spelling mean and std: 0.298 +/- 0.080\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: ivory -> I-V-O-R-Y.\n",
            "Spelling mean and std: 0.806 +/- 0.220\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: sapphire -> S-A-P-P-I-Z-R.\n",
            "Spelling mean and std: 0.521 +/- 0.291\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: orchard -> O-R-H-C-O-R-D.\n",
            "Spelling mean and std: 0.615 +/- 0.172\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: absolve -> A-B-E-L-O-R-V.\n",
            "Spelling mean and std: 0.477 +/- 0.387\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mosaic -> M-A-I-S-T.\n",
            "Spelling mean and std: 0.258 +/- 0.287\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: onset -> O-N-S-T.\n",
            "Spelling mean and std: 0.413 +/- 0.112\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: fume -> F-U-M-E.\n",
            "Spelling mean and std: 0.643 +/- 0.371\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: resolve -> R-E-S-L-I-S-S.\n",
            "Spelling mean and std: 0.464 +/- 0.237\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: mirth -> M-I-R-T.\n",
            "Spelling mean and std: 0.596 +/- 0.118\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: sphinx -> S-P-H-R-X.\n",
            "Spelling mean and std: 0.595 +/- 0.276\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: velvet -> V-E-L-O-V-T.\n",
            "Spelling mean and std: 0.300 +/- 0.391\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: maze -> M-A-Z-E.\n",
            "Spelling mean and std: 0.627 +/- 0.333\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n",
            "=====\n",
            "Completion example first line: void -> V-O-N-T.\n",
            "Spelling mean and std: 0.113 +/- 0.321\n",
            "Letter-dash-letter rewards mean and std: 1.000 +/- 0.000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=270, training_loss=0.0007303232378843758, metrics={'train_runtime': 70.7299, 'train_samples_per_second': 7.776, 'train_steps_per_second': 3.817, 'total_flos': 0.0, 'train_loss': 0.0007303232378843758})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Student task: Set the GRPOConfig and initialize the trainer\n",
        "# See: https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
        "# TODO: Complete the sections with **********\n",
        "\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "\n",
        "training_args = GRPOConfig(\n",
        "    output_dir=\"data/spelling-grpo\",\n",
        "    max_completion_length=30,\n",
        "    logging_steps=5,\n",
        "    learning_rate=5e-4,\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=8,\n",
        "    num_generations=4,\n",
        "    lr_scheduler_type='cosine',\n",
        "    beta=0,\n",
        ")\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    # Add the parameter for the reward functions\n",
        "    # **********\n",
        "    reward_funcs=[reward_spelling, reward_response_in_form_of_letter_dash_letter],\n",
        "    args=training_args,\n",
        "    train_dataset=ds[\"train\"],\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30d14200",
      "metadata": {},
      "source": [
        "Now we define the `SFTTrainer` and run the fine-tuning process."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e30c443c",
      "metadata": {},
      "source": [
        "## Step 5. Evaluate the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6f806e1d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lgw/code/genai/.venv/lib/python3.13/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proposed: T-I-R-U-M-P-H | Actual: T-R-I-U-M-P-H | Matches: ❌\n",
            "Proposed: S-A-P-P-A-L-I-R | Actual: S-A-P-P-H-I-R-E | Matches: ❌\n",
            "Proposed: E-X-P-S-T | Actual: E-X-P-O-S-E | Matches: ❌\n",
            "Proposed: F-R-S-E-S-C-O | Actual: F-R-E-S-C-O-S | Matches: ❌\n",
            "Proposed: W-I-P-S | Actual: W-I-S-P | Matches: ❌\n",
            "Proposed: M-I-R-G-R-E | Actual: M-I-R-A-G-E | Matches: ❌\n",
            "Proposed: I-V-O-R-Y | Actual: I-V-O-R-Y | Matches: ✅\n",
            "Proposed: O-N-S-T | Actual: O-N-S-E-T | Matches: ❌\n",
            "Proposed: E-L-U-D-E | Actual: E-L-U-D-E | Matches: ✅\n",
            "Proposed: S-P-H-I-N-X | Actual: S-P-H-I-N-X | Matches: ✅\n",
            "Proposed: B-R-A-W-N | Actual: B-R-A-W-N | Matches: ✅\n",
            "Proposed: G-O-S-S-O-P-I | Actual: G-O-S-S-I-P-Y | Matches: ❌\n",
            "Proposed: E-N-C-H-A-T | Actual: E-N-C-H-A-N-T | Matches: ❌\n",
            "Proposed: T-A-T-A-R-N | Actual: T-A-V-E-R-N | Matches: ❌\n",
            "Proposed: W-H-I-C-T | Actual: W-H-I-S-T-L-E | Matches: ❌\n",
            "Proposed: C-U-P-R-E-S | Actual: C-A-P-T-U-R-E | Matches: ❌\n",
            "Proposed: E-C-H-O-R | Actual: E-C-H-O | Matches: ❌\n",
            "Proposed: M-I-R-T | Actual: M-I-R-T-H | Matches: ❌\n",
            "Proposed: C-R-I-S-P | Actual: C-R-I-S-P | Matches: ✅\n",
            "Proposed: Z-E-A-L-O-W-S | Actual: Z-E-A-L-O-U-S | Matches: ❌\n",
            "14.376190476190475/20.0 words correct\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the fine-tuned model on the same training examples\n",
        "# No changes needed in this cell\n",
        "\n",
        "proportion_correct = 0.0\n",
        "\n",
        "for example in ds[\"train\"].select(range(20)):\n",
        "    prompt = example[\"prompt\"]\n",
        "    completion = example[\"spelling\"]\n",
        "    result = check_spelling(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        prompt=prompt,\n",
        "        actual_spelling=completion,\n",
        "        max_new_tokens=20,\n",
        "    )\n",
        "    proportion_correct += result\n",
        "\n",
        "print(f\"{proportion_correct}/20.0 words correct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bbfe48f",
      "metadata": {},
      "source": [
        "The model now performs better on the training data it has seen. But has it generalized? Let's check its performance on the unseen test set."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b02ba61",
      "metadata": {},
      "source": [
        "It looks like it has improved! Perhaps with a larger dataset and more training, it could get even better."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed16c690",
      "metadata": {},
      "source": [
        "## Congratulations for completing the exercise! 🎉\n",
        "\n",
        "✅ You did it! You successfully fine-tuned a small language model using PEFT with LoRA to teach it a new skill: spelling! You saw how the base model failed completely at the task, and with a very small amount of data and a short training run, the model started to learn how to spell."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f093a0b",
      "metadata": {},
      "source": [
        "<br /><br /><br /><br /><br /><br /><br /><br /><br />"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "genai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
